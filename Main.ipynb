{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasrSiala/Detection___Tracking/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tgFRh_Qid8jV"
      },
      "outputs": [],
      "source": [
        "# Installing ffmpeg\n",
        "!apt-get -qq install ffmpeg\n",
        "\n",
        "# import the library\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTy31z6veG6z",
        "outputId": "107a106c-317f-47a1-9371-f5a6a56dc9f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Detection___Tracking'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NasrSiala/Detection___Tracking.git\n",
        "os.chdir('Detection___Tracking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSCxehx2eI5V"
      },
      "outputs": [],
      "source": [
        "# Read file\n",
        "classFile  = \"coco_class_labels.txt\"\n",
        "with open(classFile) as fp:\n",
        "    labels = fp.read().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mboUoHkAeL_Z"
      },
      "outputs": [],
      "source": [
        "modelFile  = \"frozen_inference_graph.pb\"\n",
        "configFile = \"ssd_mobilenet_v2_coco_2018_03_29.pbtxt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSpqHyWxeOpl"
      },
      "outputs": [],
      "source": [
        "# Read the Tensorflow network\n",
        "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-2qSBUheQKo"
      },
      "outputs": [],
      "source": [
        "# For each file in the directory\n",
        "def detect_objects(net, im, dim = 300):\n",
        "\n",
        "    # Create a blob from the image\n",
        "    blob = cv2.dnn.blobFromImage(im, 1.0, size=(dim, dim), mean=(0, 0, 0), swapRB=True, crop=False)\n",
        "\n",
        "    # Pass blob to the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Peform Prediction\n",
        "    objects = net.forward()\n",
        "    return objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNaNFwGSecqi"
      },
      "outputs": [],
      "source": [
        "FONTFACE = cv2.FONT_HERSHEY_SIMPLEX\n",
        "FONT_SCALE = 0.7\n",
        "THICKNESS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk8jcA1sepOC"
      },
      "outputs": [],
      "source": [
        "def display_text(im, text, x, y):\n",
        "    # Get text size\n",
        "    textSize = cv2.getTextSize(text, FONTFACE, FONT_SCALE, THICKNESS)\n",
        "    dim = textSize[0]\n",
        "    baseline = textSize[1]\n",
        "\n",
        "    # Use text size to create a black rectangle\n",
        "    cv2.rectangle(\n",
        "        im,\n",
        "        (x, y - dim[1] - baseline),\n",
        "        (x + dim[0], y + baseline),\n",
        "        (0, 0, 0),\n",
        "        cv2.FILLED,\n",
        "    )\n",
        "\n",
        "    # Display text inside the rectangle\n",
        "    cv2.putText(\n",
        "        im,\n",
        "        text,\n",
        "        (x, y - 5),\n",
        "        FONTFACE,\n",
        "        FONT_SCALE,\n",
        "        (0, 255, 255),\n",
        "        THICKNESS,\n",
        "        cv2.LINE_AA,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYekc6IIemId"
      },
      "outputs": [],
      "source": [
        "def display_objects(im, objects, threshold=0.25):\n",
        "    rows = im.shape[0]\n",
        "    cols = im.shape[1]\n",
        "\n",
        "    # For every Detected Object\n",
        "    for i in range(objects.shape[2]):\n",
        "        # Find the class and confidence\n",
        "        classId = int(objects[0, 0, i, 1])\n",
        "        score = float(objects[0, 0, i, 2])\n",
        "\n",
        "        # Recover original coordinates from normalized coordinates\n",
        "        x = int(objects[0, 0, i, 3] * cols)\n",
        "        y = int(objects[0, 0, i, 4] * rows)\n",
        "        w = int(objects[0, 0, i, 5] * cols - x)\n",
        "        h = int(objects[0, 0, i, 6] * rows - y)\n",
        "\n",
        "        # Check if the detection is of good quality\n",
        "        if score > threshold:\n",
        "            display_text(im, \"{}\".format(labels[classId]), x, y)\n",
        "            cv2.rectangle(im, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
        "\n",
        "    return im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTrdDcP-ejbY"
      },
      "outputs": [],
      "source": [
        "# Read video\n",
        "source = 'City Traffic.mp4'\n",
        "cap = cv2.VideoCapture(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A0DOxt1eh9n"
      },
      "outputs": [],
      "source": [
        "# Default resolutions of the frame are obtained.\n",
        "# Convert the resolutions from float to integer.\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.\n",
        "out_mp4 = cv2.VideoWriter(\"Out.mp4\", cv2.VideoWriter_fourcc(*\"XVID\"), 100, (frame_width, frame_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KkdOVhpeeW4"
      },
      "outputs": [],
      "source": [
        "# Read until video is completed\n",
        "while cap.isOpened():\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret:\n",
        "      objects = detect_objects(net, frame)\n",
        "      frame = display_objects(frame, objects, 0.2)\n",
        "      # Write the frame to the output files\n",
        "      out_mp4.write(frame)\n",
        "\n",
        "    # Break the loop\n",
        "    else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hky-rI9Le1wW"
      },
      "outputs": [],
      "source": [
        "# When everything done, release the VideoCapture and VideoWriter objects\n",
        "cap.release()\n",
        "out_mp4.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyjXp6Wke0TI"
      },
      "outputs": [],
      "source": [
        "# Change video encoding of mp4 file from XVID to h264\n",
        "!ffmpeg -y -i \"/content/Out.mp4\" -c:v libx264 \"Out_x264.mp4\"  -hide_banner -loglevel error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7_NMexFkezIp",
        "outputId": "7de9c9bd-9eec-4d8f-ac1a-e16858928b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "#CREATE FINAL FILE\n",
        "mp4 = open(\"/content/Out.mp4\", \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(f\"\"\"<video width=700 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN57TipSkdD2r5xEmYKDunZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}